---
title: scraping data from wiki to analyze olympic medal
author: Geebbon
date: '2018-03-24'
slug: scraping-data-from-wiki-to-analyze-olympic-medal
categories:
  - web
tags:
  - R
  - web
summary:
  "Learn Edwin Thoen from R-blogger"
---

Today I learn Edwin Thoen from R-blogger. The topic is how to scrape the data from wikepedia and tidy the data in a format in which they can be analyzed. Thank Edwin for sharing the code.

* scrape data from website

I use `rvest` and `tidy` package.
```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
library("rvest")
library(tidyverse)
library(stringr)
Olympics_2018_wiki <- read_html("https://en.wikipedia.org/wiki/List_of_2018_Winter_Olympics_medal_winners")
sports <- html_nodes(Olympics_2018_wiki, "h2") %>% html_text()
sports %>% head(3)
```

`html_text` is used to convert the `xml` nodes to regular R characters. I get 18 strings, first 15 elements contain the sport's names with "edit", next step is to remove "edit" parts.

```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}

sports <- 
  sports %>% 
  `[`(1:15) %>% 
  str_split("\\[") %>% 
  map_chr(1)
```

In the above [ is used ad prefix function for subsetting, rather than its usual usage object[index]. `purrr::map_chr` will select the first element of each vector and store the result in a single character vector. This part get the olympic event name list.

```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
medals <- html_nodes(Olympics_2018_wiki, "table") %>%
  html_table() %>% 
  `[`(3:26)
```

For some reasons I checked manually that the 3rd up until the 26th table contain the results. Now, if you visit the wiki page you will notice that some sports have a single results table (such as Curling), while others have several (for women’s, for men’s, and some even for mixed events). I counted on the website the number of tables for each sport.


```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
tables_by_sport <- c(3, 3, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2)
```


